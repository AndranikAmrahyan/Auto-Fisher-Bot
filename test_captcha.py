# https://aistudio.google.com/u/1/usage?project=gen-lang-client-0290532217&timeRange=last-1-day&tab=rate-limit
import os
import asyncio
import io
import re
from dotenv import load_dotenv
from google import genai
from google.genai import types
from PIL import Image

# 1. Load Environment Variables
load_dotenv()
API_KEY = os.getenv("GEMINI_API_KEY")

if not API_KEY:
    print("‚ùå Error: GEMINI_API_KEY not found in .env file.")
    exit(1)

# ================= CONFIGURATION =================
# Change the model name here to test different versions
# Options from the link above:
# "gemini-2.5-flash", "gemini-2.5-flash-lite", "gemini-robotics-er-1.5-preview", 
MODEL_NAME = "gemini-2.5-flash-lite"

IMAGE_PATH = "Img/sword3.jpg"

# In the real bot, these options come from the telegram buttons.
# For this test, we simulate a list of options. 
# Update this list to match what is usually in your captcha (or leave it generic).
SIMULATED_BUTTON_OPTIONS = ["‚è∞", "‚öî", "üíº", "üí∏", "ü•µ", "üíç"]
# =================================================

async def test_solve_captcha():
    print(f"üîÑ Initializing Gemini Client with model: {MODEL_NAME}...")
    
    try:
        client = genai.Client(api_key=API_KEY)
    except Exception as e:
        print(f"‚ùå Failed to create client: {e}")
        return

    # 2. Load Image
    if not os.path.exists(IMAGE_PATH):
        print(f"‚ùå Error: Image not found at {IMAGE_PATH}")
        print("   Please create the folder 'Img' and put a file named 'captcha.jpg' inside.")
        return

    print(f"üìÇ Reading image from: {IMAGE_PATH}")
    raw_img_bytes = None
    try:
        with open(IMAGE_PATH, "rb") as f:
            raw_img_bytes = f.read()
    except Exception as e:
        print(f"‚ùå Error reading file: {e}")
        return

    # === –ò–ù–¢–ï–ì–†–ê–¶–ò–Ø: –û–ë–†–ê–ë–û–¢–ö–ê –ò–ó–û–ë–†–ê–ñ–ï–ù–ò–Ø (CROP) ===
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º PIL –¥–ª—è –æ–±—Ä–µ–∑–∫–∏ –ø—Ä–∞–≤–æ–π —á–∞—Å—Ç–∏ (—Ç–µ–∫—Å—Ç "–ü–†–û–í–ï–†–ö–ê –ù–ê –†–û–ë–û–¢–ê...")
    final_image_data = raw_img_bytes
    try:
        with Image.open(io.BytesIO(raw_img_bytes)) as img:
            width, height = img.size
            # –û—Ç—Ä–µ–∑–∞–µ–º ~35% —Å–ø—Ä–∞–≤–∞, –æ—Å—Ç–∞–≤–ª—è–µ–º –ª–µ–≤—ã–µ 65%
            crop_width = int(width * 0.65)
            
            # –û–±—Ä–µ–∑–∞–µ–º: (left, top, right, bottom)
            cropped_img = img.crop((0, 0, crop_width, height))
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≤ –±—É—Ñ–µ—Ä
            output_buffer = io.BytesIO()
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ RGB –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
            if img.mode in ("RGBA", "P"):
                cropped_img = cropped_img.convert("RGB")
                
            cropped_img.save(output_buffer, format="JPEG")
            final_image_data = output_buffer.getvalue()
            print("‚úÇÔ∏è Image cropped successfully (removed right 35%)")
    except Exception as pil_err:
        print(f"‚ö†Ô∏è Warning: PIL processing failed, using original image: {pil_err}")
        final_image_data = raw_img_bytes

    # 3. Prepare Prompt (Updated from main.py)
    prompt = (
        f"This is a captcha check. The image contains one MAIN object which is significantly LARGER than the others. "
        f"There are also small decoy icons and chaotic lines - IGNORE them. "
        f"Look strictly for the single BIGGEST visual element in the image. "
        f"Compare this biggest object with the following emoji options: {', '.join(SIMULATED_BUTTON_OPTIONS)}. "
        f"Reply with ONLY the single emoji character from the list that matches the biggest object. "
        f"Do not write explanations."
    )

    print(f"üì§ Sending request to Google AI...")
    
    try:
        # 4. API Call
        response = await asyncio.to_thread(
            client.models.generate_content,
            model=MODEL_NAME,
            contents=[
                types.Part.from_bytes(data=final_image_data, mime_type="image/jpeg"),
                prompt
            ]
        )

        # 5. Output Result with Smart Parsing
        if response.text:
            raw_answer = response.text.strip()
            print(f"\nüì© Raw API Response: '{raw_answer}'")
            
            # === –ò–ù–¢–ï–ì–†–ê–¶–ò–Ø: –£–ú–ù–´–ô –ü–ê–†–°–ò–ù–ì –û–¢–í–ï–¢–ê ===
            predicted_emoji = None
            
            # 1. –¢–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ
            if raw_answer in SIMULATED_BUTTON_OPTIONS:
                predicted_emoji = raw_answer
            
            # 2. –ü–æ–∏—Å–∫ —ç–º–æ–¥–∑–∏ –≤–Ω—É—Ç—Ä–∏ —Ç–µ–∫—Å—Ç–∞ (–µ—Å–ª–∏ –Ω–µ—Ç —Ç–æ—á–Ω–æ–≥–æ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è)
            if not predicted_emoji:
                # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã –∏–∑ SIMULATED_BUTTON_OPTIONS, –∫–æ—Ç–æ—Ä—ã–µ –ò–ò —É–ø–æ–º—è–Ω—É–ª –≤ —Å–≤–æ–µ–º –æ—Ç–≤–µ—Ç–µ
                found_options = [opt for opt in SIMULATED_BUTTON_OPTIONS if opt in raw_answer]
                
                if len(found_options) == 1:
                    # –ï—Å–ª–∏ –Ω–∞–π–¥–µ–Ω —Ä–æ–≤–Ω–æ –æ–¥–∏–Ω –≤–∞—Ä–∏–∞–Ω—Ç ‚Äî —ç—Ç–æ –Ω–∞—à –≤—ã–±–æ—Ä
                    predicted_emoji = found_options[0]
                elif len(found_options) > 1:
                    # –ï—Å–ª–∏ –ò–ò —É–ø–æ–º—è–Ω—É–ª –±–æ–ª—å—à–µ –æ–¥–Ω–æ–≥–æ –≤–∞—Ä–∏–∞–Ω—Ç–∞ –∏–∑ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –∫–Ω–æ–ø–æ–∫
                    print("\n" + "="*30)
                    print("‚ùå FAILURE (AMBIGUOUS RESPONSE)")
                    print(f"‚ùì Found multiple options: {found_options}")
                    print(f"üìÑ Full response: {raw_answer}")
                    print("="*30 + "\n")
                    return # Stop here as per logic
            
            if predicted_emoji:
                print("\n" + "="*30)
                print(f"‚úÖ SUCCESS!")
                print(f"ü§ñ Model: {MODEL_NAME}")
                print(f"üéØ Decoded Answer: {predicted_emoji}")
                print("="*30 + "\n")
            else:
                print("\n" + "="*30)
                print("‚ùå FAILURE (NO MATCH)")
                print("‚ö†Ô∏è No valid emoji from the list found in response.")
                print("="*30 + "\n")

        else:
            print("‚ö†Ô∏è Response received but text was empty.")

    except Exception as e:
        print(f"\n‚ùå API Error: {e}")
        if "404" in str(e):
            print("   (Hint: The model name might be wrong or not available in your region)")
        if "429" in str(e):
            print("   (Hint: Quota exceeded or rate limit reached)")

def list_available_models():
    print(f"üîÑ Authenticating with Google GenAI...")
    try:
        client = genai.Client(api_key=API_KEY)
        
        print("\nüìã Fetching list of available models...\n")
        
        pager = client.models.list()
        
        found_any = False
        print(f"{'Model Name (ID)':<40} | {'Display Name'}")
        print("-" * 70)
        
        for model in pager:
            found_any = True
            print(f"{model.name:<40} | {model.display_name}")
            
        print("-" * 70)
        
        if not found_any:
            print("‚ö†Ô∏è No models found. Check your API key permissions.")
            
    except Exception as e:
        print(f"‚ùå Error listing models: {e}")

if __name__ == "__main__":
    # list_available_models()
    asyncio.run(test_solve_captcha())
